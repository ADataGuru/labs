{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1hltZ4m60q1"
   },
   "source": [
    "# Pyspark - Preprocessing\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### Description\n",
    "\n",
    "Dans ce TP, vous allez approfondir vos connaissances sur PySpark, une bibliothèque Python très populaire pour l'analyse et la modélisation de données volumineuses. Ici, vous apprendrez à créer un ensemble de données à l'aide de la bibliothèque PySpark, et à le manipuler en utilisant des techniques de filtrage et de découpage standard.\n",
    "\n",
    "Vos compétences en matière de gestion des données seront mises à l'épreuve et, à la fin de ce laboratoire, vous devriez avoir une compréhension approfondie de la façon dont PySpark fonctionne en pratique pour construire des pipelines d'analyse de données.\n",
    "\n",
    "\n",
    "\n",
    "#### Objectifs d'apprentissage\n",
    "\n",
    "À la fin de ce laboratoire, vous serez en mesure de :\n",
    "\n",
    "- Créer une Session Spark, et stocker les données dans un Spark DataFrame ;\n",
    "- Interroger des données avec PySpark en utilisant le SQL standard ;\n",
    "- Créer une nouvelle colonne à l'intérieur du Spark DataFrame ;\n",
    "- Effectuer un nettoyage standard des données - cohérence des types, filtrage, découpage en tranches ;\n",
    "- Pivoter et manipuler un DataFrame Spark.\n",
    "\n",
    "#### Public Cible\n",
    "\n",
    "Ce laboratoire est destiné à :\n",
    " - Ceux qui sont intéressés à effectuer des analyses de données avec Python.\n",
    " - Toute personne impliquée dans la science des données et les pipelines d'ingénierie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prérequis\n",
    "\n",
    "#### Connaissances :\n",
    "Vous devez posséder :\n",
    " - Une compréhension intermédiaire de Python.\n",
    " - Une connaissance de base de SQL.\n",
    " - Une connaissance de base des bibliothèques suivantes : Pandas.\n",
    "\n",
    "#### Prérequis installations\n",
    "\n",
    "- Installer apache Spark\n",
    "- Java 8 car spark est ecrit en scala et qu'il lui faut donc une JVM (java virtual machine)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KXsYhrPw88g",
    "outputId": "82bb79b4-b1fc-4ba7-89e5-3e58cd32a017"
   },
   "outputs": [],
   "source": [
    "!apt install openjdk-8-jdk-headless -qq\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgtGKySmBD0W"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3XVg8dhu4Ii"
   },
   "source": [
    "### Initialiser une SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATiOEKEwp6B_"
   },
   "source": [
    "Introduisons un objet très important dans `pyspark` : le `SparkSession`. La Session Spark est un point d'entrée unifié d'une application spark à partir de Spark 2.0. Avant son introduction, le `SparkContext` était le point d'entrée de toute application spark, et nécessitait un `SparkConf`, qui avait toutes les configurations de cluster et les paramètres pour créer un objet Spark Context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InrpJmuArRM8"
   },
   "source": [
    "Nous importons donc du sous-module Spark SQL la classe `SparkSession`, et nous instancions une session en utilisant la méthode `getOrCreate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "btlEFBq-xpiG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/06/28 07:50:19 WARN Utils: Your hostname, MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.20.10.6 instead (on interface en0)\n",
      "22/06/28 07:50:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/06/28 07:50:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "# sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB9B5y2sq-nG"
   },
   "source": [
    "Spark SQL fournit `spark.read().csv(\"nom_fichier\")` pour lire un fichier ou un répertoire de fichiers au format CSV dans Spark DataFrame : utilisons cette méthode pour ingérer notre jeu de données. Nous spécifions `header=True` pour importer la première ligne du csv comme en-tête du dataframe Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-WgrQLlzmyt",
    "outputId": "919fbd57-c5f6-43a0-d2a3-c538e7e3a42e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77|   2|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26|   5|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43|   3|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://raw.githubusercontent.com/ADataGuru/labs/lab/map-reduce/modules/batch/spark/tp/data/tips.csv\"\n",
    "import pandas as pd\n",
    "pd_df = pd.read_csv(file_path)\n",
    "tips = spark.createDataFrame(pd_df)\n",
    "tips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eV-SSrNcXrH9",
    "outputId": "a84ab6f6-c7f2-4482-adc9-7fc0c3c9757d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPlq87sguugm"
   },
   "source": [
    "Comme nous pouvons le voir, une simple inspection de l'objet `tips` confirme que nous avons affaire à un DataFrame Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpHLACDQsWI-"
   },
   "source": [
    "Cool ! Mais il nous manque un aspect crucial, qui peut être expliqué comme suit. Techniquement parlant, un Spark DataFrame est conceptuellement équivalent à une table dans une base de données relationnelle, et il est fréquent d'utiliser cette définition pour identifier un Spark DataFrame. En particulier, les tables Spark peuvent être de deux types. Temporaires ou permanentes. Ces deux types de tables sont présents dans une base de données. Si nous ne spécifions pas de base de données, Spark utilise la base de données `par défaut`. Nous pouvons voir la liste des bases de données disponibles avec `listDatabases`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xJmxZMmtfcB",
    "outputId": "4278c34e-6122-4c15-f095-0fce00171ec7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Database(name='default', description='default database', locationUri='file:/Users/loic.caminale/Workspace/formation/dataguru/labs/modules/batch/spark-101/spark-warehouse')]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVRJSismuUwb"
   },
   "source": [
    "Si nous inspectons les tables disponibles, nous voyons facilement qu'il n'y a pas de tables disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iS1ZkZvlt9bj",
    "outputId": "02f0f116-e967-471d-f723-afdd5dd776c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Aex6l-Xub5V"
   },
   "source": [
    "Pour créer une table dans la database par `default`, nous allons utiliser la méthode `createOrReplaceTempView`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2E1g6x4pwy24"
   },
   "outputs": [],
   "source": [
    "tips.createOrReplaceTempView(\"tips\") # Add tips data to the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQY5kVdtuk1d",
    "outputId": "202c7e3b-ea8b-4a1e-c619-303259013881"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Table(name='tips', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNrch0mQu0Fl"
   },
   "source": [
    "### Requêter la donnée avec Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwHeIIHWxAz2"
   },
   "source": [
    "L'avantage de la table Spark est que nous pouvons exécuter n'importe quelle requête avec le SQL standard. Ainsi, par exemple, supposons que nous souhaitons inspecter les 10 premières lignes de la table `tips`. En SQL standard, cela se traduit par la requête suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1x_zCoeGvDVi"
   },
   "outputs": [],
   "source": [
    "QUERY_TIPS = \"FROM tips SELECT * LIMIT 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U78Wv0mDxOfy"
   },
   "source": [
    "Nous pouvons maintenant passer la requête au module `sql` comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KnlCQTkzjuP",
    "outputId": "77292b60-99c1-4927-a770-e55075ccee6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77|   2|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips10 = spark.sql(QUERY_TIPS)\n",
    "tips10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02b0gbJ7xwlS"
   },
   "source": [
    "Il existe une interaction entre un DataFrame (ou table) Spark et un DataFrame Pandas : en effet, nous pouvons convertir une table Spark en un DataFrame Pandas en utilisant la fonction `toPandas`. Cela peut être utile, en particulier pour les data scientists qui souhaitent utiliser Pandas au cas où ils auraient besoin d'effectuer des manipulations plus avancées ou simplement d'intégrer une pipeline Python plus complexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "yedGIkZAzRHA",
    "outputId": "2ce60682-9932-4b84-8bcc-54a7a8bfa2ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  total_bill   tip     sex smoker  day    time size\n0      16.99  1.01  Female     No  Sun  Dinner    2\n1      10.34  1.66    Male     No  Sun  Dinner    3\n2      21.01   3.5    Male     No  Sun  Dinner    3\n3      23.68  3.31    Male     No  Sun  Dinner    2\n4      24.59  3.61  Female     No  Sun  Dinner    4\n5      25.29  4.71    Male     No  Sun  Dinner    4\n6       8.77     2    Male     No  Sun  Dinner    2\n7      26.88  3.12    Male     No  Sun  Dinner    4\n8      15.04  1.96    Male     No  Sun  Dinner    2\n9      14.78  3.23    Male     No  Sun  Dinner    2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_bill</th>\n      <th>tip</th>\n      <th>sex</th>\n      <th>smoker</th>\n      <th>day</th>\n      <th>time</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16.99</td>\n      <td>1.01</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.34</td>\n      <td>1.66</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.01</td>\n      <td>3.5</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23.68</td>\n      <td>3.31</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24.59</td>\n      <td>3.61</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>25.29</td>\n      <td>4.71</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8.77</td>\n      <td>2</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>26.88</td>\n      <td>3.12</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>15.04</td>\n      <td>1.96</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14.78</td>\n      <td>3.23</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips10 = spark.sql(QUERY_TIPS)\n",
    "tips10_df = tips10.toPandas()\n",
    "tips10_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnaSLSzbzdab"
   },
   "source": [
    "Essayons d'écrire une requête sql `group by` comme suit. Nous voulons compter le nombre de clients par jour et par sexe. Pour cela, vous devez écrire une requête qui effectue les opérations suivantes :\n",
    " - SELECTIONNER les colonnes `jour`, `sexe` et `COUNT(*)` ;\n",
    " - depuis la table `tips` ;\n",
    " - GROUPER PAR les colonnes `day` et `sex` ;\n",
    " - ORDER PAR la colonne `day`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HJkbYMWc0SPe"
   },
   "outputs": [],
   "source": [
    "STUDENT_QUERY = \"SELECT day, sex, COUNT(*) as N FROM tips GROUP BY day, sex ORDER BY day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfWbZwi09LET",
    "outputId": "2b4e9719-c80d-4980-9ae8-a5eb84b06e85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "(8, 3)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_counts = spark.sql(STUDENT_QUERY)\n",
    "pd_counts = tips_counts.toPandas() # Convert the results to a pandas DataFrame\n",
    "pd_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHbDDtFz8zM_"
   },
   "source": [
    "## Créer une nouvelle colonne avec PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GatKlEl0jjS"
   },
   "source": [
    "Le traitement des données avec PySpark est assez simple. Par exemple, supposons que nous souhaitons ajouter une nouvelle colonne à la table spark `tips`. Pour ce faire, nous utilisons la méthode `withColumn`, qui retourne un nouveau DataFrame en ajoutant une colonne ou en remplaçant la colonne existante qui a le même nom. L'expression de la colonne doit être une expression sur ce DataFrame.\n",
    "\n",
    "Supposons, par exemple, que nous voulions calculer le pourcentage de pourboires par rapport à la facture totale. Nous avons besoin de deux colonnes du tableau d'origine : le `tip` et le `total_bill`. Donc, dans le `withColumn`, nous spécifions :\n",
    " - le nom des nouvelles colonnes sous forme de chaîne. Dans notre cas : `perc_tips` ;\n",
    " - l'expression de la colonne basée sur les colonnes des tables existantes. Dans notre cas : `(tips.tip/tips.total_bill)*100`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckQJxVWjAPKq",
    "outputId": "f83995c6-a463-4636-f285-3b8100bf162c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|         perc_tips|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|5.9446733372572105|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|16.054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|16.658733936220845|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 13.97804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|14.680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4| 18.62396204033215|\n",
      "|      8.77|   2|  Male|    No|Sun|Dinner|   2| 22.80501710376283|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|11.607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|13.031914893617023|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|21.853856562922868|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 16.65043816942551|\n",
      "|     35.26|   5|Female|    No|Sun|Dinner|   4|14.180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|10.181582360570687|\n",
      "|     18.43|   3|  Male|    No|Sun|Dinner|   4|16.277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|20.364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|18.164967562557923|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 16.16650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|22.774708410067525|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|20.624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|16.222760290556902|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = spark.table(\"tips\")\n",
    "tips = tips.withColumn(\"perc_tips\", (tips.tip/tips.total_bill)*100)\n",
    "tips.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkbV9O7-16fe"
   },
   "source": [
    "### Pivoter une table Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uA4Z-0I3Paf"
   },
   "source": [
    "Nous pouvons même effectuer des transformations de données directement avec pyspark : par exemple, supposons que nous soyons intéressés à obtenir le nombre total de clients par leur sexe. Nous pouvons appeler directement dans l'onglet `tips` la méthode `groupBy`, en spécifiant la colonne sur laquelle nous souhaitons agréger - dans notre cas `sex`.\n",
    "\n",
    "Pour agréger sur la colonne `sex`, nous utilisons la méthode `count()`, qui calcule le nombre total d'occurrences par sexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MiZBk9zs2Hi1",
    "outputId": "51c74491-4135-4da0-969f-2404b3e357a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   sex|count|\n",
      "+------+-----+\n",
      "|Female|   87|\n",
      "|  Male|  157|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "by_sex = tips.groupBy(\"sex\")\n",
    "by_sex.count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JpGuden31i4"
   },
   "source": [
    "Nous pouvons évidemment spécifier une méthode d'agrégation différente : par exemple, nous pourrions être intéressés par le calcul du pourcentage moyen de conseils par sexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "n2WrYaMp12hm"
   },
   "outputs": [],
   "source": [
    "by_gender = tips.groupBy(\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-yi7wwh14xQ",
    "outputId": "1964f5fa-2907-4b79-deaa-2641a0f5c63d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|   sex|    avg(perc_tips)|\n",
      "+------+------------------+\n",
      "|Female|16.649073632892485|\n",
      "|  Male|15.765054700429744|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "by_gender.avg(\"perc_tips\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKZy0RJCgWNi"
   },
   "source": [
    "### Convertion de types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnqMSCIn4_FH"
   },
   "source": [
    "Parfois, nous voulons être sûrs que les données sont stockées correctement dans notre table. Une bonne caractéristique de la méthode `withColumn` est qu'elle permet également de remplacer des colonnes existantes, ce qui signifie que nous pouvons même remplacer le type existant de la colonne. Mais comment pouvons-nous faire cela ?\n",
    "\n",
    "Eh bien, c'est assez simple : en appelant la méthode `withColumn`, on spécifie le nom de la colonne, puis l'expression de la colonne en appliquant la méthode `cast` sur celle-ci. De cette façon, nous pouvons facilement attribuer un nouveau type à une colonne existante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "G1TWhPivgV2M"
   },
   "outputs": [],
   "source": [
    "tips = tips.withColumn(\"total_bill\",tips.total_bill.cast(\"double\"))\n",
    "tips = tips.withColumn(\"tip\", tips.tip.cast(\"double\"))\n",
    "tips = tips.withColumn(\"size\", tips.size.cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67mRQot0h-Vm",
    "outputId": "619fc382-ce89-40fb-de69-7f719664c5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|         perc_tips|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|5.9446733372572105|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|16.054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|16.658733936220845|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 13.97804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|14.680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4| 18.62396204033215|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| 22.80501710376283|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|11.607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|13.031914893617023|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|21.853856562922868|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 16.65043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|14.180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|10.181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|16.277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|20.364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|18.164967562557923|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 16.16650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|22.774708410067525|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|20.624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|16.222760290556902|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5kJ72Qc7SVR"
   },
   "source": [
    "Essayons d'effectuer une agrégation en utilisant la méthode `groupBy` comme suit. Nous voulons calculer le pourboire moyen par sexe et par fumeur. Pour ce faire, vous devez appliquer la méthode `groupBy` sur les `tips` en spécifiant, à l'intérieur de l'appel `groupBy`, les colonnes `\"smoker\"` et `\"sex\"`, séparées par une virgule. Assurez-vous de stocker cet objet dans la variable `by_smoker_sex_table`.\n",
    "\n",
    "Ensuite, appliquez sur la table `by_smoker_sex_table` le `avg(\"tip\")`, qui agrège la valeur du pourboire par fumeur et par sexe. Ici, l'agrégation est le pourboire moyen par rapport aux colonnes spécifiées. Veillez à appeler la méthode `show()` à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEb_JP9i7QIa",
    "outputId": "e6075532-dfa0-4c7b-d434-c3763859c662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------+\n",
      "|smoker|   sex|          avg(tip)|\n",
      "+------+------+------------------+\n",
      "|    No|Female|2.7735185185185185|\n",
      "|    No|  Male|  3.11340206185567|\n",
      "|   Yes|  Male|3.0511666666666666|\n",
      "|   Yes|Female| 2.931515151515151|\n",
      "+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "by_smoker_sex_table = tips.groupBy(\"smoker\", \"sex\")\n",
    "by_smoker_sex_table.avg(\"tip\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "xXi7eUID8RKL",
    "outputId": "5399aede-b970-4e1b-d346-3c3e093304f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Female'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_smoker_sex_df = by_smoker_sex_table.avg(\"tip\").toPandas() # Convert the results to a pandas DataFrame\n",
    "by_smoker_sex_df.iloc[0,1] # must be \"Female\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hyy4gouVzqp6"
   },
   "source": [
    "### Découpage d'une table avec `select'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sWj09SI6Eky"
   },
   "source": [
    "In case we wish to select just a few columns, we can use the `select` method, which allows to select the desired columns, and it returns a temporary view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbvGsN2Rzq1f",
    "outputId": "be58117a-9265-491e-cb8e-e8d59a6a470e"
   },
   "outputs": [],
   "source": [
    "# Select the correct columns\n",
    "tips_000 = tips.select(\"total_bill\", \"tip\", \"size\", \"perc_tips\")\n",
    "tips_000.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC9ZiJl7811e"
   },
   "source": [
    "### Filtrer une table avec `filter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_SaJzGX61G1"
   },
   "source": [
    "Nous avons deux façons distinctes d'effectuer un filtrage avec une table Spark :\n",
    " 1. en utilisant une expression de chaîne dans la méthode `filter` ;\n",
    " 2. en utilisant une condition booléenne dans la méthode `filter`.\n",
    "\n",
    "En particulier, ici nous voulons effectuer une condition de filtrage simple, à savoir choisir tous les enregistrements avec une `total_bill` supérieure à 40 USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzmi4uux8qzc"
   },
   "source": [
    "#### Filtrage avec une condition string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "bHD9Yfio8xB5",
    "outputId": "57760b3e-ddbb-495a-a171-6132b9416fae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   total_bill    tip     sex smoker   day    time  size  perc_tips\n0       48.27   6.73    Male     No   Sat  Dinner     4  13.942407\n1       40.17   4.73    Male    Yes   Fri  Dinner     4  11.774956\n2       44.30   2.50  Female    Yes   Sat  Dinner     3   5.643341\n3       41.19   5.00    Male     No  Thur   Lunch     5  12.138869\n4       48.17   5.00    Male     No   Sun  Dinner     6  10.379905\n5       50.81  10.00    Male    Yes   Sat  Dinner     3  19.681165\n6       45.35   3.50    Male    Yes   Sun  Dinner     3   7.717751\n7       40.55   3.00    Male    Yes   Sun  Dinner     2   7.398274\n8       43.11   5.00  Female    Yes  Thur   Lunch     4  11.598237\n9       48.33   9.00    Male     No   Sat  Dinner     4  18.621974",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_bill</th>\n      <th>tip</th>\n      <th>sex</th>\n      <th>smoker</th>\n      <th>day</th>\n      <th>time</th>\n      <th>size</th>\n      <th>perc_tips</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>48.27</td>\n      <td>6.73</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sat</td>\n      <td>Dinner</td>\n      <td>4</td>\n      <td>13.942407</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40.17</td>\n      <td>4.73</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>Fri</td>\n      <td>Dinner</td>\n      <td>4</td>\n      <td>11.774956</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44.30</td>\n      <td>2.50</td>\n      <td>Female</td>\n      <td>Yes</td>\n      <td>Sat</td>\n      <td>Dinner</td>\n      <td>3</td>\n      <td>5.643341</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41.19</td>\n      <td>5.00</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Thur</td>\n      <td>Lunch</td>\n      <td>5</td>\n      <td>12.138869</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48.17</td>\n      <td>5.00</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>6</td>\n      <td>10.379905</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50.81</td>\n      <td>10.00</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>Sat</td>\n      <td>Dinner</td>\n      <td>3</td>\n      <td>19.681165</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>45.35</td>\n      <td>3.50</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n      <td>7.717751</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>40.55</td>\n      <td>3.00</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n      <td>7.398274</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>43.11</td>\n      <td>5.00</td>\n      <td>Female</td>\n      <td>Yes</td>\n      <td>Thur</td>\n      <td>Lunch</td>\n      <td>4</td>\n      <td>11.598237</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>48.33</td>\n      <td>9.00</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sat</td>\n      <td>Dinner</td>\n      <td>4</td>\n      <td>18.621974</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_01 = tips.filter(\"total_bill>40\").toPandas()\n",
    "tips_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1ECSQXu8wli"
   },
   "source": [
    "#### Filtrage avec une condition booléen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "95olzmfo8v-y",
    "outputId": "5349978a-6665-45e6-acbe-07de3ecb98e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   total_bill    tip     sex smoker   day    time  size  perc_tips\n0       48.27   6.73    Male     No   Sat  Dinner     4  13.942407\n1       40.17   4.73    Male    Yes   Fri  Dinner     4  11.774956\n2       44.30   2.50  Female    Yes   Sat  Dinner     3   5.643341\n3       41.19   5.00    Male     No  Thur   Lunch     5  12.138869\n4       48.17   5.00    Male     No   Sun  Dinner     6  10.379905\n5       50.81  10.00    Male    Yes   Sat  Dinner     3  19.681165\n6       45.35   3.50    Male    Yes   Sun  Dinner     3   7.717751\n7       40.55   3.00    Male    Yes   Sun  Dinner     2   7.398274\n8       43.11   5.00  Female    Yes  Thur   Lunch     4  11.598237\n9       48.33   9.00    Male     No   Sat  Dinner     4  18.621974",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_bill</th>\n      <th>tip</th>\n      <th>sex</th>\n      <th>smoker</th>\n      <th>day</th>\n      <th>time</th>\n      <th>size</th>\n      <th>perc_tips</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>48.27</td>\n      <td>6.73</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sat</td>\n      <td>Dinner</td>\n      <td>4</td>\n      <td>13.942407</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40.17</td>\n      <td>4.73</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>Fri</td>\n      <td>Dinner</td>\n      <td>4</td>\n      <td>11.774956</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44.30</td>\n      <td>2.50</td>\n      <td>Female</td>\n      <td>Yes</td>\n      <td>Sat</td>\n      <td>Dinner</td>\n      <td>3</td>\n      <td>5.643341</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41.19</td>\n      <td>5.00</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Thur</td>\n      <td>Lunch</td>\n      <td>5</td>\n      <td>12.138869</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48.17</td>\n      <td>5.00</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>6</td>\n      <td>10.379905</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50.81</td>\n      <td>10.00</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>Sat</td>\n      <td>Dinner</td>\n      <td>3</td>\n      <td>19.681165</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>45.35</td>\n      <td>3.50</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n      <td>7.717751</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>40.55</td>\n      <td>3.00</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n      <td>7.398274</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>43.11</td>\n      <td>5.00</td>\n      <td>Female</td>\n      <td>Yes</td>\n      <td>Thur</td>\n      <td>Lunch</td>\n      <td>4</td>\n      <td>11.598237</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>48.33</td>\n      <td>9.00</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sat</td>\n      <td>Dinner</td>\n      <td>4</td>\n      <td>18.621974</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_02 = tips.filter(tips.total_bill>40).toPandas() # Filter tips with a boolean\n",
    "tips_02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj428AvfmzYV"
   },
   "source": [
    "Nous pouvons même appliquer plusieurs filtrages en chaine :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "X9uDOYKh-mJT"
   },
   "outputs": [],
   "source": [
    "filterA = tips.sex == \"Female\"\n",
    "filterB = tips.day == \"Sun\"\n",
    "tips_03 = tips.filter(filterA).filter(filterB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKmzcJ_U0UB7",
    "outputId": "9acc9ca6-74b5-4aea-dbca-87c40738d0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|         perc_tips|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|5.9446733372572105|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|14.680764538430255|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|14.180374361883155|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|20.364126770060686|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 16.16650532429816|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|20.624631703005306|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2| 25.26724975704568|\n",
      "|     34.81| 5.2|Female|    No|Sun|Dinner|   4|14.938236139040505|\n",
      "|     25.71| 4.0|Female|    No|Sun|Dinner|   3|15.558148580318942|\n",
      "|     17.31| 3.5|Female|    No|Sun|Dinner|   2|20.219526285384173|\n",
      "|     29.85|5.14|Female|    No|Sun|Dinner|   5|17.219430485762143|\n",
      "|      25.0|3.75|Female|    No|Sun|Dinner|   4|              15.0|\n",
      "|     13.39|2.61|Female|    No|Sun|Dinner|   2| 19.49215832710978|\n",
      "|     16.21| 2.0|Female|    No|Sun|Dinner|   3|12.338062924120912|\n",
      "|     17.51| 3.0|Female|   Yes|Sun|Dinner|   2|17.133066818960593|\n",
      "|       9.6| 4.0|Female|   Yes|Sun|Dinner|   2| 41.66666666666667|\n",
      "|      20.9| 3.5|Female|   Yes|Sun|Dinner|   3| 16.74641148325359|\n",
      "|     18.15| 3.5|Female|   Yes|Sun|Dinner|   3| 19.28374655647383|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips_03.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GH4fX3emuOr"
   },
   "source": [
    "Une autre application intéressante de cette fonctionnalité est que nous pouvons supprimer les valeurs nulles avec une simple chaîne de caractères. Par exemple, si l'on souhaite supprimer toutes les références pour lesquelles la valeur `total_bill` est nulle, il suffit de passer à l'appel `filter` la chaîne `\"total_bill is not NULL\"`. C'est cool, n'est-ce pas ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUY5LiwO9o6_",
    "outputId": "4eab22dd-a1b6-48e3-92dd-3654d3a499e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|         perc_tips|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|5.9446733372572105|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|16.054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|16.658733936220845|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 13.97804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|14.680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4| 18.62396204033215|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| 22.80501710376283|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|11.607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|13.031914893617023|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|21.853856562922868|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 16.65043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|14.180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|10.181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|16.277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|20.364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|18.164967562557923|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 16.16650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|22.774708410067525|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|20.624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|16.222760290556902|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips_counts = tips.filter(\"total_bill is not NULL\")\n",
    "tips_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSKIpzEpCrSf"
   },
   "source": [
    "Essayons d'effectuer une agrégation en utilisant la méthode `groupBy` comme suit. Comme nous l'avons fait précédemment, nous voulons calculer le pourboire moyen pour un homme non-fumeur. Pour ce faire, nous pouvons filtrer les `tips` par sexe et fumeur, comme suit :\n",
    " - filter by `tips.sex=='Male'`\n",
    " - filtrer par `tips.smoker=='No'`\n",
    "\n",
    "et ensuite vous `groupBy().avg('perc_tips')`. Veillez à appeler la méthode `show()` à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "LcoI-s7fAax-",
    "outputId": "35a66b7f-cc3d-44ff-b755-1eab2a808368"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   avg(perc_tips)\n0       16.066872",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg(perc_tips)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16.066872</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_table = tips.filter(tips.sex=='Male').filter(tips.smoker=='No').groupBy().avg('perc_tips')\n",
    "exercise_table_df = exercise_table.toPandas()\n",
    "exercise_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZyDrJy-Ue2g"
   },
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Validation Check\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# ====================================\n",
    "vcf_02 =  int(exercise_table_df.iloc[0,0])\n",
    "with open('results/vcf_02.txt', 'w') as f:\n",
    "    f.write(\"%s\\n\" % vcf_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4blq1Qpig3F"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "spark-preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}